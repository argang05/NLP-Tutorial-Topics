{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dce2ab1-97cd-40db-ba38-58817370f2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0a3ecc1-160c-4c72-be29-81ff0d3e32df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the large version of spacy as it supports word vectors\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36c5afe8-59ed-4ad9-acef-336b3072f26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog  | Vector:  True  | OOV : False\n",
      "cat  | Vector:  True  | OOV : False\n",
      "banana  | Vector:  True  | OOV : False\n",
      "afsksfsd  | Vector:  False  | OOV : True\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"dog cat banana afsksfsd\")\n",
    "\n",
    "for token in doc:\n",
    "    # Checking Whether it contains vector of is a Out Of Vocabulary Word:\n",
    "    print(token.text,\" | Vector: \",token.has_vector,\" | OOV :\",token.is_oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d190518f-f2a9-4c6b-9350-c56312732aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing a vector:\n",
    "doc[0].vector\n",
    "doc[0].vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb2e2b74-ca1e-40b8-8254-189dc0985eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_token = nlp(\"bread\")\n",
    "base_token.vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "348c9147-cf9d-41e5-b75f-5b61aff70c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bread <-> bread :  0.9999999744752309\n",
      "sandwich <-> bread :  0.6341067010130894\n",
      "burger <-> bread :  0.47520687769584247\n",
      "car <-> bread :  0.06451533308853552\n",
      "tiger <-> bread :  0.04764611675903374\n",
      "human <-> bread :  0.2151154210812192\n",
      "wheat <-> bread :  0.6150360888607199\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp(\"bread sandwich burger car tiger human wheat\")\n",
    "\n",
    "#Checking similarity between base_token and the tokens in doc2:\n",
    "for token in doc2:\n",
    "    print(f\"{token.text} <-> {base_token.text} : \", token.similarity(base_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e90c1171-6073-484b-a1d0-ff80987438a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a Dedicated Function For Printing Similarities:\n",
    "\n",
    "def print_similarity(base_word , words_to_comapare):\n",
    "    base_token = nlp(base_word)\n",
    "    docmt = nlp(words_to_comapare)\n",
    "    #Checking similarity between base_token and the tokens in docmt:\n",
    "    for token in docmt:\n",
    "        print(f\"{token.text} <-> {base_token.text} : \", token.similarity(base_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2706cc3a-0870-4f67-a062-085ded8cbd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple <-> iphone :  0.4387907401919904\n",
      "samsung <-> iphone :  0.670859081425417\n",
      "iphone <-> iphone :  1.000000072144752\n",
      "dog <-> iphone :  0.08211864228011527\n",
      "kitten <-> iphone :  0.10222317834969896\n"
     ]
    }
   ],
   "source": [
    "print_similarity(\"iphone\" , \"apple samsung iphone dog kitten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c99f1aa4-5b6d-4511-88ad-ed3e16047f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solving Word Arithmetic Using Word Vectors:\n",
    "king = nlp.vocab[\"king\"].vector\n",
    "man = nlp.vocab[\"man\"].vector\n",
    "woman = nlp.vocab[\"woman\"].vector\n",
    "queen = nlp.vocab[\"queen\"].vector\n",
    "\n",
    "result = king - man + woman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa1fe597-c901-4d41-bb9f-260d33fabb52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.61780137]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Similarity between result and queen using cosine similarity:\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarity([result] , [queen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c152045-121a-4db7-a2fa-4f61141499ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
